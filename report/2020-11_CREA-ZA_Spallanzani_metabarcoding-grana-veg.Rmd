---
title: "Newtech - Metagenomics on milk (Spallanzani + CREA-ZA)"
author: "Nelson Nazzicari"
date: "`r Sys.Date()`"
output: 
  html_document:
    css: CREA.css
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, echo=FALSE, include=FALSE, message=FALSE}
library(knitr)
options(knitr.kable.NA = ' ', digits = 3) #this is for kable
library(ggplot2)
library(plyr)
library(printr)
library(DT)
library(xfun)
xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))

source('~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/script/data_manager.R')
infolder = '~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/delivery_20200706/'
delivery_20200706 = load_all_OTU_files(infolder)
infolder = '~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/delivery_20201009/'
delivery_20201009 = load_all_OTU_files(infolder)
raw_OTUs = c(delivery_20200706, delivery_20201009)

```

```{r cheatsheet, echo=FALSE, include=FALSE, eval=FALSE}
# EVALUATE CODE?  eval=TRUE
# PRINT CODE?     echo=TRUE
# PRINT OUTPUT?   include=TRUE
# UNWANTED STUFF? message=FALSE warning=FALSE error=FALSE

#attach a file (e.g. an xls)
xfun::embed_file('some_file.xls')

#data table with fancy selectors and searches
DT::datatable(cars)

#more humble data table
kable(cars, caption = "my cars")
```

```{r echo=FALSE, include=TRUE}
#this is your standard R chunk
```

# Document history

<!--
To highlight changes use
<span class="new"> your stuff </span>
-->

* 2020-11-04 - initial report
* 2020-11-09 - added section on bovine genome
* 2020-11-16 - added section on filtering, control samples

# Aim

Metabarcoding analysis on Grana Padano milk, focusing on vegetable presence.

# Available samples

```{r echo=FALSE, include=TRUE}
samples = read.csv('~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/Transcodifica Campioni_cleaned.csv', stringsAsFactors = FALSE, row.names = 1)
samples = samples[,c("Id_Lab", "type", "caseificio", "MESE", "data_prelievo")]
samples$province = sapply(samples$caseificio, FUN = substr, start=1, stop=2)
samples[samples$province == '', 'province'] = '-'
```

## By type

```{r echo=FALSE, include=TRUE}
samples_summary = ddply(samples, .(type), function(x){
  return(data.frame(
    samples = nrow(x),
    Id_Lab = paste(collapse = ', ', x$Id_Lab)
  ))
})

kable(samples_summary)
```

where "broken" indicates a non viable sample which was then re-sent and sequenced, "ctrl" indicate pure vegetable samples (e.g. fodder), "grana" and "non-grana" indicates milk samples from inside and outside Grana Padano areas, respectively.

## By province

```{r echo=FALSE, include=TRUE}
#from here on we don't need the broken samples anymore
samples = subset(samples, type != 'broken')

samples_summary = ddply(samples, .(province), function(x){
  return(data.frame(
    samples = nrow(x),
    Id_Lab = paste(collapse = ', ', x$Id_Lab)
  ))
})

kable(samples_summary)
```

## By extraction method

Two extraction methods have been tested but at the end we will only work with phenol.

# Fraction of Bovine genome

After a mail exchange with Slobodanka Radovic I obtained the OTU table for the second delivery, containing the numerosities for 27 samples, plus the sequences for each of the 4811 centroids analyzed.

A first analysis of the centroid cumulative numerosity led to the following plot:

```{r echo=FALSE, include=TRUE, eval=TRUE}

#read the OTU table
OTU = read.csv('~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/otu_table-2.csv', stringsAsFactors = FALSE, row.names = 1)
OTU$taxonomy = NULL

#getting the top 30 of most present centroids
centroids_cnt = rowSums(OTU)
OTU = OTU[order(centroids_cnt, decreasing = TRUE),]

#cumulative plot
centroids_cum = centroids_cnt
for (i in 1:length(centroids_cnt)){
  centroids_cum[i] = sum(centroids_cnt[1:i])
}
centroids_cum = centroids_cum / sum(centroids_cnt)

plot(centroids_cum, xlab = 'Centroids, sorted by numerosity', ylab = 'Cumulative reads, relative')
```

For reference, the 10 most numerous centroids account for the `r centroids_cum[10] * 100` % of all the reads.

To investigate what fraction of the available reads have bovine origin I've blasted the centroid sequences on the 
*Bos Taurus* genome via the [NCBI website](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastSearch&PROG_DEF=blastn&BLAST_PROG_DEF=megaBlast&BLAST_SPEC=OGP__9913__10708).

```{r echo=FALSE, include=TRUE, eval=TRUE}
al = rbind(
  read.csv('~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/centroids/lines1-5000_Alignment-HitTable.csv', stringsAsFactors = FALSE, header = FALSE),
  read.csv('~/research/CREA-ZA_Spallanzani_metabarcoding-grana-veg/data/private/centroids/lines5001-end_Alignment-HitTable.csv', stringsAsFactors = FALSE, header = FALSE)
)

#giving column names, for what we are interested in
colnames(al) = c('id1', 'id2', 'perc_id', 'match_length', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'e_value', 'bit_score')

#removing duplicates
al = ddply(al, .(id1), function(x){
  i = which.min(x$e_value)
  return(x[i,])
})

#filtering
al = subset(al, perc_id>0.95 & e_value < 0.00001 )

#how many of the reads are bovine
bovine_reads = sum(centroids_cnt[al$id1])

```
The sequencing results are filtered with the following criteria:

* percent identity > 0.95
* e-value < 1e-5
* in case of multiple alignments I keep the one with smallest e_value

After the filtering `r nrow(al)` centroids align on the bovine genome, representing the `r 100*nrow(al)/length(centroids_cnt)` % of the total `r length(centroids_cnt)` centroids. In terms of reads, the `r 100*bovine_reads/sum(centroids_cnt)` % of reads are bovine.

## OPEN QUESTION 1: what fraction of unassigned data is bovine, exactly?
So far I've done a high level analysis of centroids, but it would be better to operate sample-by-sample.

# Filtering and conventions

This filtering strategy is taken straighforward from the [published paper on metabarcoding in grana padano](https://www.sciencedirect.com/science/article/pii/S0740002020302021?casa_token=pwjIEIBIUI0AAAAA:UAhVfUNTpp9OOG_iTAWkdc9GKUiy4cd1Ho2On19p80QX8MZHb-MCbDbnFn3a66D3DTn8XqerzTk). We may want to review these values at a later time. The current plan is:

* entries having less than 5 reads are removed and binned to unassigned (UN)
* entries (species?) representing 1% of the reads of a sample will be labeled "subdominant" and will be considered less important in the analysis

The taxonomic hierarchy we used is:

* reads
* domain
* clade/phylum
* class
* order
* family
* subfamily
* tribe
* subtribe
* genus
* species

with some levels (e.g. clade, subtribe) are often absent.

# Control samples

In this section I focus on the three control samples: GT ("MANGIME X GP"), N ("NUCLEO"), S ("SOIA"). 

```{r echo=FALSE, include=TRUE}
level = 'domain'
OTU_ctrl = build_OTU_table(raw_OTUs, level) 

#subset to control
sel = OTU_ctrl$meta$type == 'ctrl'
OTU_ctrl = filter_OTU(OTU_ctrl, sel)

kable(OTU_ctrl$meta, row.names = FALSE)
```

Taking a look at the assigned **domains** we get:

```{r echo=FALSE, include=TRUE}
kable(OTU_ctrl$OTU_rel_screen, row.names = TRUE, col.names = paste(colnames(OTU_ctrl$OTU_rel), '%'))
```

Where "UN" means unassigned reads. All in all most of the reads are assigned, as expected in control samples. If we go deeper into the taxonomic tree, at **family** level we find (click on column names to reorder):

```{r echo=FALSE, include=TRUE}
level = 'family'
OTU_ctrl = build_OTU_table(raw_OTUs, level) 

#subset to control
sel = OTU_ctrl$meta$type == 'ctrl'
OTU_ctrl = filter_OTU(OTU_ctrl, sel)

#transpose, for ease of reading
df = data.frame(t(OTU_ctrl$OTU_rel_screen))
colnames(df) = OTU_ctrl$meta$Id_Lab
DT::datatable(df)
```

This table still is quite usable, but shows a trend: the number of unassigned entries grows when we go deeper into the
taxonomy tree. We already have about 8% of unassigned reads for GT and N, and if we go down to **species** level:

```{r echo=FALSE, include=TRUE}
level = 'species'
OTU_ctrl = build_OTU_table(raw_OTUs, level) 

#subset to control
sel = OTU_ctrl$meta$type == 'ctrl'
OTU_ctrl = filter_OTU(OTU_ctrl, sel)

#transpose, for ease of reading
df = data.frame(t(OTU_ctrl$OTU_rel_screen))
colnames(df) = OTU_ctrl$meta$Id_Lab
DT::datatable(df)
```

This is to show that we may need to operate at a level different from **species**, or risk losing a lot of information.

## OPEN QUESTION 2: what taxonomic level?
How to decide what taxonomic level to use? I've read a few metabarcoding papers that use phylum/family. Would it be ok? Further data exploration will probably give us more hints.